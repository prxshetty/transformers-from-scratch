{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86e95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9919335246086121}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I am  very u happy man  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe51acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is one of the best foods I have ever had in this city',\n",
       " 'labels': ['review', 'news', 'vlog', 'politics'],\n",
       " 'scores': [0.781644344329834,\n",
       "  0.18876691162586212,\n",
       "  0.0271689984947443,\n",
       "  0.002419769996777177]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero shot classification\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is one of the best foods I have ever had in this city\",\n",
    "    candidate_labels=[\"politics\", \"review\", \"vlog\", \"news\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168f252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"It doesnt matter what you do for a living, what matters is that you provide support to others that you don't actually need.\\n\\nDo you have a job? Do you want to pay for your kids' education? Do you have a job\"},\n",
       " {'generated_text': \"It doesnt matter what you do for a living, what matters is you live and you work, or you pay taxes. You don't pay taxes, you pay taxes. And you make a living. It's the way you do.\\n\\nI\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text generation\n",
    "generator = pipeline(\"text-generation\", num_return_sequences = 2,max_length = 200)\n",
    "generator(\"It doesnt matter what you do for a living, what matters is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bcb15ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' How do you feel to be among the first to receive this message?\\n\\nWhat are your thoughts on the recent controversy concerning the death penalty in the United States?\\n\\nWhat rights and responsibilities do you have as a citizen?\\n\\nWhat are your thoughts on the death penalty?\\n\\nWhat do you think of the death penalty?\\n\\nWhat are your thoughts on the death penalty?\\n\\nCan you give examples of when it is appropriate to use the death penalty?\\n\\nCan you give examples of when it is not appropriate to use the death penalty?\\n\\nCan you give examples of when there are no more death penalty cases in your state?\\n\\nCan you give examples of when there is a shortage of death penalty cases?\\n\\nWhat are your thoughts on the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat is your opinion on the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat are your thoughts on the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat are the pros and cons of the death penalty?\\n\\nWhat'},\n",
       " {'generated_text': ' How do you feel to be among the first and only to have your name on that record?\"\\n\\nHe hesitated a moment.\\n\\n\"I was a slave. I was born in slavery, and I was bought as a child by a man who did not even know that I was a woman. I was not allowed to read or write. I was given the best care I could get, but I was never allowed to read. There was no education, no language, no music, no hope, no belief. I was not allowed to dream.\"\\n\\nNora shook her head.\\n\\n\"I have never heard of a slave who did not dream. I have not known a slave who did not dream. I have never seen a slave who did not dream.\"\\n\\n\"You do realize that you have never seen a slave who did not dream?\"\\n\\nShe nodded.\\n\\n\"So, why do you question my dreams?\"\\n\\n\"Because you are a white woman who is not a slave. Your dreams are not a dream for a slave.\"\\n\\n\"I am not a slave, but I have dreams.\"\\n\\n\"Your dreams are not mine then.\"\\n\\n\"I will not accept that you have a right to tell me what I can dream and what I cannot'},\n",
       " {'generated_text': ' How do you feel to be among the first to see the new information?\\n\\nWhat is the process for making decisions in a team?\\n\\nHow do you resolve disagreements or conflicts in a team setting?\\n\\nHow do you develop a process of dealing with change?\\n\\nHow do you effectively deal with power differentials within a team?\\n\\nWhat are some of the techniques for making decisions in a group setting?\\n\\nWhat are some of the techniques for dealing with power differentials among team members?\\n\\nWhat are some of the techniques for dealing with conflict in a team setting?\\n\\nHow does conflict affect relationships among team members?\\n\\nWhat are some of the techniques for handling interpersonal conflict effectively?\\n\\nWhat are some of the techniques for dealing with the effects of stress on team members?'},\n",
       " {'generated_text': ' How do you feel to be among the first to achieve a breakthrough? What are your plans to leverage this breakthrough into business?\\n\\n\\nThe Role of the CEO in the\\xa0Future\\n\\n\\nIn today’s world, the CEO is the primary decision-maker, as most companies are now more than ever, led by a single person. From a financial standpoint, the CEO is the head of all the financial decisions a company is making.\\xa0\\n\\nThe CEO’s role is to make sure the company’s future is positive and profitable. However, the CEO can’t do this alone, as there are many other people who play a role in the company’s future.\\n\\nThe role of the CEO in the future\\n\\n\\nThe CEO’s role is multifaceted, and it includes more than just making big financial decisions. The CEO’s role includes everything a company can do to help it grow and become more successful. Some of the things that a CEO may do include:\\n\\n  • Leading the company staff:\\xa0The CEO is the primary decision-maker in any given company. They are in charge of making all the important decisions, and they need to get the best out of their employees.\\xa0\\n  • Hiring and promoting:\\xa0The CEO needs to hire the right people to help the'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model = \"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator(\" How do you feel to be among the\", max_length = 200, num_return_sequences = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2691515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8988337516784668,\n",
       "  'token': 119,\n",
       "  'token_str': '.',\n",
       "  'sequence': \"My best friend ' s girlfriend has the biggest.\"},\n",
       " {'score': 0.0695207342505455,\n",
       "  'token': 136,\n",
       "  'token_str': '?',\n",
       "  'sequence': \"My best friend ' s girlfriend has the biggest?\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model = \"bert-base-cased\")\n",
    "unmasker(\"My best friend's girlfriend has the biggest [MASK]\", top_k = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c623e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n",
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.99922496),\n",
       "  'word': 'John Wick',\n",
       "  'start': 11,\n",
       "  'end': 20},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9980305),\n",
       "  'word': 'Atlanta',\n",
       "  'start': 48,\n",
       "  'end': 55},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.53518987),\n",
       "  'word': 'Rochester',\n",
       "  'start': 64,\n",
       "  'end': 73}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities = True)\n",
    "ner(\"My name is John Wick and I work at a startup in Atlanta show at Rochester\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1e6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.4096326231956482, 'start': 31, 'end': 42, 'answer': 'a cave mine'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\")\n",
    "qa( question = \"where do you think I work\", context = \"My name is Roman and I work in a cave mine setting stones for a priest valley\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7044d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n",
      "Your max_length is set to 142, but your input_length is only 40. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' You have the right to perform your prescribed duties, but you are not entitled to the fruits of your actions . Never consider yourself the cause of the results, nor be attached to inaction, nor the result of your inaction . You are not responsible for your actions, but for your performance .'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "You have the right to perform your prescribed duties, but you are not entitled to the fruits of your actions. Never consider yourself the cause of the results, nor be attached to inaction\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa07b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Your input_length: 34 is bigger than 0.9 * max_length: 20. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Do you want to make a small speech without having been able to make a small speech?'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model = \"snehalyelmati/mt5-hindi-to-english\")\n",
    "translator ( \"क्या आप चाहेंगे कि मैं सिर्फ छोटे वाक्य बनाऊँ (जैसे संवाद की तरह), या लंबा अनुच्छेद?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa51289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'lynx, catamount', 'score': 0.4335002601146698}, {'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 'score': 0.034796182066202164}, {'label': 'snow leopard, ounce, Panthera uncia', 'score': 0.032401859760284424}, {'label': 'Egyptian cat', 'score': 0.023944782093167305}, {'label': 'tiger cat', 'score': 0.022889139130711555}]\n"
     ]
    }
   ],
   "source": [
    "image_classifier  = pipeline(task = \"image-classification\", model = \"google/vit-base-patch16-224\")\n",
    "result = image_classifier(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9a7e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps:0\n",
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ',!'}\n"
     ]
    }
   ],
   "source": [
    "transcriber = pipeline(task = \"automatic-speech-recognition\", model = \"openai/whisper-large-v3\")\n",
    "result = transcriber (    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    " ) \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26f3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
