{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464ac8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3043f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1941afcd9e4ca9aa2fc3f0611450b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c652f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "eli5 = load_dataset(\"dany0407/eli5_category\", split = \"train[:5000]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78107d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5 = eli5.train_test_split(test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624ede6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '767kyu',\n",
       " 'title': \"How does a radio station send metadata like song name to my car's radio?\",\n",
       " 'selftext': \"I was driving in my car, and for the first time noticed that the name of the current song on the radio was scrolling across the little LCD screen, and I wondered how that metadata works from the radio station's perspective.\",\n",
       " 'category': 'Technology',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers': {'a_id': ['dobwoc6', 'doc0znu'],\n",
       "  'text': ['Modulation became more efficient, which opened up space in the guard bands to transmit digital information on a sub carrier. Edit : okay imagine that while recording the song the radio station was tapping out a special code in the background of the song that only your car radio could hear. That code is the meta data.',\n",
       "   \"You're seeing the effects of the Radio Data System (RDS). Basically the radio stations encode simple data as a series of a high-frequency (inaudible to humans) tones which a decoder in your radio can detect and decode. RDS is used for other things too like traffic information (many dedicated GPS units can tap into this) and clock synchronization.\"],\n",
       "  'score': [24, 13],\n",
       "  'text_urls': [[], []]},\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6f8d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee19af2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': '767kyu',\n",
       " 'title': \"How does a radio station send metadata like song name to my car's radio?\",\n",
       " 'selftext': \"I was driving in my car, and for the first time noticed that the name of the current song on the radio was scrolling across the little LCD screen, and I wondered how that metadata works from the radio station's perspective.\",\n",
       " 'category': 'Technology',\n",
       " 'subreddit': 'explainlikeimfive',\n",
       " 'answers.a_id': ['dobwoc6', 'doc0znu'],\n",
       " 'answers.text': ['Modulation became more efficient, which opened up space in the guard bands to transmit digital information on a sub carrier. Edit : okay imagine that while recording the song the radio station was tapping out a special code in the background of the song that only your car radio could hear. That code is the meta data.',\n",
       "  \"You're seeing the effects of the Radio Data System (RDS). Basically the radio stations encode simple data as a series of a high-frequency (inaudible to humans) tones which a decoder in your radio can detect and decode. RDS is used for other things too like traffic information (many dedicated GPS units can tap into this) and clock synchronization.\"],\n",
       " 'answers.score': [24, 13],\n",
       " 'answers.text_urls': [[], []],\n",
       " 'title_urls': ['url'],\n",
       " 'selftext_urls': ['url']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5 = eli5.flatten()\n",
    "eli5[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab26f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    return tokenizer([\" \".join(x) for x in example[\"answers.text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957c86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd310ca075d4c03b72bd9cad4de2ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84225a0293c4c11bb0730b11d3d75f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1197 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3437 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_eli5 = eli5.map(\n",
    "    preprocess_function, \n",
    "    batched = True, \n",
    "    num_proc = 4, \n",
    "    remove_columns = eli5[\"train\"].column_names, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ee1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "def group_texts(examples):\n",
    "    concatenated_examples = {k : sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    result = {\n",
    "        k :[t[i: i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd599af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b347153ac26f4938afe2878df80d19be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1835973732e5423fa899b4e2a88ace35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "031f96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9758e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399eafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bb/_7c_tp6x5yz_39tq724bm5pc0000gn/T/ipykernel_38488/4065628419.py:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3921' max='3921' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3921/3921 16:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.918000</td>\n",
       "      <td>3.842024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.825900</td>\n",
       "      <td>3.831560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.784500</td>\n",
       "      <td>3.829508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/pranamshetty/Developer/workshop/transformers-from-scratch/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3921, training_loss=3.8455089830798905, metrics={'train_runtime': 972.6906, 'train_samples_per_second': 32.249, 'train_steps_per_second': 4.031, 'total_flos': 1024544559071232.0, 'train_loss': 3.8455089830798905, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"first_eli5_clm-model\", \n",
    "    eval_strategy = \"epoch\", \n",
    "    learning_rate = 2e-5, \n",
    "    weight_decay = 0.01, \n",
    "    push_to_hub = True, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    args = training_args, \n",
    "    train_dataset = lm_dataset['train'],\n",
    "    eval_dataset = lm_dataset['test'], \n",
    "    data_collator = data_collator, \n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5984cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='329' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [329/329 00:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity : 46.04\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity : {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521f62af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7ddf16210f4a5ca820645126ec2e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c34bb2cb0194423aa7d99e53705c45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eef11d9c5014141913bdb05b70b49e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...st_eli5_clm-model/training_args.bin: 100%|##########| 5.78kB / 5.78kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0f7d55cc70445d8860be499b5aa07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...st_eli5_clm-model/model.safetensors:   0%|          |  550kB /  328MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/prxshetty/first_eli5_clm-model/commit/97fc2fa725d5dc2fd8eff465129c1b578db356bc', commit_message='End of training', commit_description='', oid='97fc2fa725d5dc2fd8eff465129c1b578db356bc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/prxshetty/first_eli5_clm-model', endpoint='https://huggingface.co', repo_type='model', repo_id='prxshetty/first_eli5_clm-model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d3e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Somatic hypermutation allows the immune system to \"immediately\" respond by \"getting\" their body to \"expand\" it. This can be achieved by using this technique called \"intermediate immunization,\" which can be accomplished by the immune system\\'s body using specialized techniques to control the immune systems\\' responses. If you look at a tumor, you see a huge amount of cells around it and it\\'s going to get bigger and larger. It\\'s what causes cancer cells to grow, and that\\'s why they\\'re important. There are more cells in the tumor than normal, and we don\\'t know how much they grow. Immunization works by giving the immune system \"specific\" immune responses to the cells, but not how much the immune system gets to. When you cut off the lymphatic system, it\\'s not really that much to the brain, but to the brain as well. It\\'s basically the same thing. \"You can\\'t survive without a normal cell to process all the different things it needs to survive,\" says David Blain. \"You don\\'t have to fight off the lymphatic system to survive, you just need to be able to survive without being able to survive.\" So the immune system will just get bigger (literally) and bigger, and that\\'s why we need to treat all of this'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "prompt = \"Somatic hypermutation allows the immune system to\"\n",
    "output = pipeline(\"text-generation\", model = \"prxshetty/first_eli5_clm-model\")\n",
    "output(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5e5568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prxshetty/first_eli5_clm-model\")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"prxshetty/first_eli5_clm-model\")\n",
    "outputs = model.generate(inputs, max_new_tokens = 100, do_sample = True, top_k = 50, top_p = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2ccf3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x17a9c8140>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Somatic hypermutation allows the immune system to adapt to a more drastic response. When the immune system is overwhelmed, the immune system does NOT adapt to new stimuli (such as allergies, etc...) The reason the immune system doesn't adapt can be because the immune system is basically the same thing as our immune system. I am not a fan of that, but I can see how the body responds to any other form of extreme stress because the immune system is already working to adapt to extreme stress. There is actually a mechanism that works so well with\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
